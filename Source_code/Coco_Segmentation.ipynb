{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Install library (Detectron2)",
   "metadata": {
    "id": "RYX4ZvCru65v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install opencv-python-headless pandas\n",
    "\n",
    "!pip install torch torchvision\n",
    "\n",
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ],
   "metadata": {
    "id": "K7Zw8Q1svEAH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Imports and utility functions",
   "metadata": {
    "id": "8lejHgAPvHlD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "\n",
    "\n",
    "def ensure_dir(p: str):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def time_from_frame(frame_idx: int, fps: float) -> float:\n",
    "    if not fps or math.isclose(fps, 0.0):\n",
    "        fps = 30.0\n",
    "    return frame_idx / fps\n",
    "\n",
    "def fmt_hms(seconds: float) -> str:\n",
    "    return str(timedelta(seconds=float(seconds))).split(\".\")[0]\n",
    "\n",
    "def build_cfg(config_path: str, weights_path: str, score_thresh: float = 0.5, device: str = \"cuda\"):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_path)\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh\n",
    "\n",
    "    # Auto-select device\n",
    "    if device.lower() in [\"cuda\", \"gpu\"] and torch.cuda.is_available():\n",
    "        cfg.MODEL.DEVICE = \"cuda\"\n",
    "        print(\"--- Configuration using: GPU (cuda) ---\")\n",
    "    else:\n",
    "        cfg.MODEL.DEVICE = \"cpu\"\n",
    "        print(\"--- Configuration using: CPU ---\")\n",
    "    return cfg\n",
    "\n",
    "def alpha_blend_mask(image, masks, colors=None, alpha=0.45):\n",
    "    \"\"\"\n",
    "    Draw a semi-transparent mask (Fast, avoids Visualizer if optimizing for FPS).\n",
    "    masks: Tensor/ndarray [N, H, W] (bool or 0/1)\n",
    "    colors: list of BGR tuples, len=N\n",
    "    \"\"\"\n",
    "    if masks is None or len(masks) == 0:\n",
    "        return image\n",
    "    if isinstance(masks, torch.Tensor):\n",
    "        masks = masks.detach().cpu().numpy()\n",
    "    overlay = image.copy()\n",
    "    N = masks.shape[0]\n",
    "    H, W = image.shape[:2]\n",
    "\n",
    "    if colors is None:\n",
    "        rng = np.random.default_rng(123)\n",
    "        colors = [tuple(int(c) for c in rng.integers(64, 255, size=3)) for _ in range(N)]  # BGR\n",
    "\n",
    "    for i in range(N):\n",
    "        m = masks[i].astype(bool)\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        color = colors[i % len(colors)]\n",
    "        overlay[m] = (0.6 * overlay[m] + 0.4 * np.array(color)).astype(np.uint8)\n",
    "\n",
    "    out = (alpha * overlay + (1 - alpha) * image).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "# --- Slot Drawing Utilities ---\n",
    "def load_and_scale_slots(slots_json_path, target_w, target_h):\n",
    "    \"\"\"Load and scale polygons from JSON file.\"\"\"\n",
    "    if not os.path.isfile(slots_json_path):\n",
    "        print(f\"âš ï¸  Slots JSON file not found: {slots_json_path}\")\n",
    "        return [], None, None\n",
    "\n",
    "    with open(slots_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    slots = data.get(\"slots\", [])\n",
    "    ref_w, ref_h = data.get(\"frame_size\", [None, None])\n",
    "\n",
    "    # Scale polygons if reference size differs from video size\n",
    "    if ref_w and ref_h and (ref_w != target_w or ref_h != target_h):\n",
    "        print(f\"--- Scaling slots from {ref_w}x{ref_h} to {target_w}x{target_h}\")\n",
    "        sx, sy = target_w / float(ref_w), target_h / float(ref_h)\n",
    "        slots = [\n",
    "            [[int(px * sx), int(py * sy)] for (px, py) in poly]\n",
    "            for poly in slots\n",
    "        ]\n",
    "\n",
    "    return slots\n",
    "\n",
    "def create_slot_masks(slots, height, width):\n",
    "    \"\"\"\n",
    "    Convert a list of polygons (slots) into a stack of binary masks.\n",
    "    \"\"\"\n",
    "    if not slots:\n",
    "        return None, None\n",
    "\n",
    "    num_slots = len(slots)\n",
    "    slot_masks = np.zeros((num_slots, height, width), dtype=np.uint8)\n",
    "    slot_areas = []\n",
    "\n",
    "    for i, poly in enumerate(slots):\n",
    "        pts = np.array(poly, dtype=np.int32)\n",
    "        mask_i = np.zeros((height, width), dtype=np.uint8)\n",
    "        cv2.fillPoly(mask_i, [pts], 1)\n",
    "        slot_masks[i] = mask_i\n",
    "        slot_areas.append(np.sum(mask_i))\n",
    "\n",
    "    return slot_masks, np.array(slot_areas)\n",
    "\n",
    "def check_slot_occupancy(detection_masks, slot_masks, slot_areas, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Check which slots are occupied based on % intersection area.\n",
    "    - detection_masks: [N, H, W] (bool/uint8), N is the number of objects\n",
    "    ...\n",
    "    \"\"\"\n",
    "    num_slots = slot_masks.shape[0]\n",
    "\n",
    "    if num_slots == 0:\n",
    "        return []\n",
    "\n",
    "    # If no objects are detected, all slots are empty\n",
    "    if detection_masks is None or len(detection_masks) == 0:\n",
    "        return [False] * num_slots\n",
    "\n",
    "    occupied_flags = [False] * num_slots\n",
    "\n",
    "    # Combine all object masks into one large mask [H, W]\n",
    "    combined_detection_mask = np.any(detection_masks, axis=0).astype(np.uint8)\n",
    "\n",
    "    for i in range(num_slots):\n",
    "        slot_area_i = slot_areas[i]\n",
    "        if slot_area_i == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate intersection\n",
    "        intersection = np.logical_and(slot_masks[i], combined_detection_mask).astype(np.uint8)\n",
    "        intersection_area = np.sum(intersection)\n",
    "\n",
    "        ratio = intersection_area / slot_area_i\n",
    "\n",
    "        if ratio >= threshold:\n",
    "            occupied_flags[i] = True\n",
    "\n",
    "    return occupied_flags\n",
    "\n",
    "def draw_slots_on_frame(frame, slots, occupied_flags=None,\n",
    "                        color_empty_bgr=(0, 128, 0),   # Green (empty)\n",
    "                        color_occupied_bgr=(0, 0, 128), # Red (occupied)\n",
    "                        thickness=2, draw_label=True):\n",
    "    \"\"\"Draw loaded polygons (slots) onto the frame, with different colors.\"\"\"\n",
    "\n",
    "    if occupied_flags is None:\n",
    "        occupied_flags = [False] * len(slots)\n",
    "\n",
    "    for i, poly in enumerate(slots, start=1):\n",
    "        pts = np.array(poly, dtype=np.int32)\n",
    "\n",
    "        is_occupied = occupied_flags[i-1]\n",
    "        color = color_occupied_bgr if is_occupied else color_empty_bgr\n",
    "\n",
    "        cv2.polylines(frame, [pts], True, color, thickness)\n",
    "\n",
    "        if draw_label:\n",
    "            cx = int(np.mean(pts[:, 0]))\n",
    "            cy = int(np.mean(pts[:, 1]))\n",
    "            cv2.putText(frame, str(i), (cx - 10, cy),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "    return frame\n",
    "\n",
    "print(\"âœ… Utility functions loaded successfully.\")"
   ],
   "metadata": {
    "id": "sBemF5SUvKDb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Main processing function process_video",
   "metadata": {
    "id": "5Eiko8A9vLnI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def process_video(\n",
    "        config_path: str,\n",
    "        weights_path: str,\n",
    "        input_video: str,\n",
    "        out_dir: str,\n",
    "        score_thresh: float = 0.5,\n",
    "        use_visualizer: bool = False,\n",
    "        mask_alpha: float = 0.45,\n",
    "        slots_json_path: str = None,\n",
    "        draw_slots: bool = False\n",
    "):\n",
    "    assert os.path.isfile(input_video), f\"Video not found: {input_video}\"\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    OCCUPANCY_THRESHOLD = 0.2\n",
    "\n",
    "    cfg = build_cfg(config_path, weights_path, score_thresh=score_thresh, device=\"cuda\")\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    dataset_name = cfg.DATASETS.TEST[0] if len(cfg.DATASETS.TEST) > 0 else None\n",
    "    meta = MetadataCatalog.get(dataset_name) if dataset_name else None\n",
    "    thing_classes = getattr(meta, \"thing_classes\", None)\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {input_video}\")\n",
    "\n",
    "    input_fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    output_fps = 30.0\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"--- Reading video: {input_video}\")\n",
    "    print(f\"--- Specs (Input): {width}x{height} @ {input_fps:.2f} FPS, Total: {total_frames} frames\")\n",
    "    print(f\"--- Specs (Output): {output_fps:.2f} FPS\")\n",
    "\n",
    "    slots = []\n",
    "    slot_masks = None\n",
    "    slot_areas = None\n",
    "    if draw_slots and slots_json_path:\n",
    "        slots = load_and_scale_slots(slots_json_path, width, height)\n",
    "        if not slots:\n",
    "            print(f\"Warning: Could not load/scale slots. Slots will not be drawn.\")\n",
    "            draw_slots = False\n",
    "        else:\n",
    "            slot_masks, slot_areas = create_slot_masks(slots, height, width)\n",
    "            if slot_masks is not None:\n",
    "                print(f\"--- Created {len(slots)} slot masks.\")\n",
    "            else:\n",
    "                print(\"Warning: Could not create slot masks.\")\n",
    "                draw_slots = False\n",
    "\n",
    "    elif draw_slots and not slots_json_path:\n",
    "        print(\"Warning: --draw_slots is enabled but --slots_json was not provided. Slots will not be drawn.\")\n",
    "        draw_slots = False\n",
    "\n",
    "    SLOT_THICKNESS = 2\n",
    "    SLOT_DRAW_LABEL = True\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(input_video))[0]\n",
    "    out_video = os.path.join(out_dir, f\"{base}_detect_overlay.avi\")\n",
    "    out_csv = os.path.join(out_dir, f\"{base}_seg.csv\")\n",
    "    out_sum = os.path.join(out_dir, f\"{base}_summary.txt\")\n",
    "\n",
    "    writer = cv2.VideoWriter(out_video, cv2.VideoWriter_fourcc(*\"XVID\"), output_fps, (width, height))\n",
    "\n",
    "    rows = []\n",
    "    frames_with_detections = 0\n",
    "    frame_idx = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        outputs = predictor(frame)\n",
    "        instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "        filtered_masks = None\n",
    "        det_count = 0\n",
    "\n",
    "        if len(instances) > 0:\n",
    "            classes = instances.pred_classes.numpy()\n",
    "            scores = instances.scores.numpy()\n",
    "            boxes = instances.pred_boxes.tensor.numpy()\n",
    "            masks = instances.pred_masks.numpy() if instances.has(\"pred_masks\") else None\n",
    "\n",
    "            filtered_masks = masks\n",
    "            det_count = len(classes)\n",
    "\n",
    "            if det_count > 0:\n",
    "                frames_with_detections += 1\n",
    "\n",
    "                if use_visualizer:\n",
    "                    v = Visualizer(frame[:, :, ::-1], metadata=meta, instance_mode=ColorMode.IMAGE)\n",
    "                    vis = v.draw_instance_predictions(instances).get_image()[:, :, ::-1]\n",
    "                    frame_out = vis\n",
    "                else:\n",
    "                    frame_out = frame.copy()\n",
    "                    if filtered_masks is not None:\n",
    "                        frame_out = alpha_blend_mask(frame_out, filtered_masks, alpha=mask_alpha)\n",
    "\n",
    "                    for i in range(det_count):\n",
    "                        x1, y1, x2, y2 = boxes[i].astype(int)\n",
    "                        score = float(scores[i])\n",
    "                        cls_id = int(classes[i])\n",
    "                        cname = thing_classes[cls_id] if (thing_classes and 0 <= cls_id < len(thing_classes)) else str(\n",
    "                            cls_id)\n",
    "\n",
    "                        cv2.rectangle(frame_out, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        cv2.putText(frame_out, f\"{cname} {score:.2f}\", (x1, max(0, y1 - 6)),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        t_sec = time_from_frame(frame_idx, input_fps)\n",
    "                        area = int(filtered_masks[i].sum()) if filtered_masks is not None else -1\n",
    "                        rows.append({\n",
    "                            \"video\": base,\n",
    "                            \"frame\": frame_idx,\n",
    "                            \"time_sec\": round(t_sec, 3),\n",
    "                            \"time_hms\": fmt_hms(t_sec),\n",
    "                            \"class_id\": cls_id,\n",
    "                            \"class_name\": cname,\n",
    "                            \"score\": round(score, 4),\n",
    "                            \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                            \"mask_area_px\": area,\n",
    "                            \"img_w\": width, \"img_h\": height\n",
    "                        })\n",
    "            else:\n",
    "                frame_out = frame\n",
    "        else:\n",
    "            frame_out = frame\n",
    "\n",
    "        # Calculate empty slot count\n",
    "        empty_slot_count = 0\n",
    "        total_slot_count = len(slots) if slots else 0\n",
    "        occupied_spaces = 0 # Default\n",
    "        occupied_flags = None\n",
    "\n",
    "        if draw_slots and slot_masks is not None:\n",
    "            occupied_flags = check_slot_occupancy(\n",
    "                filtered_masks,\n",
    "                slot_masks,\n",
    "                slot_areas,\n",
    "                threshold=OCCUPANCY_THRESHOLD\n",
    "            )\n",
    "            empty_slot_count = occupied_flags.count(False)\n",
    "            occupied_spaces = total_slot_count - empty_slot_count # Calculate occupied slots\n",
    "        elif draw_slots:\n",
    "            empty_slot_count = total_slot_count\n",
    "            occupied_flags = [False] * total_slot_count\n",
    "\n",
    "        # Draw the slots\n",
    "        if draw_slots and slots:\n",
    "            frame_out = draw_slots_on_frame(\n",
    "                frame_out,\n",
    "                slots,\n",
    "                occupied_flags=occupied_flags,\n",
    "                thickness=SLOT_THICKKNOWN,\n",
    "                draw_label=SLOT_DRAW_LABEL\n",
    "            )\n",
    "\n",
    "        hud_text = f\"Car_in_park: {det_count}\"\n",
    "\n",
    "        # Add slot info if available\n",
    "        if draw_slots and slots:\n",
    "            hud_text += f\" | Free_spaces: {empty_slot_count} | Occupied_spaces: {occupied_spaces}\"\n",
    "\n",
    "        cv2.putText(frame_out, hud_text,\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.7,\n",
    "                    (255, 255, 255),\n",
    "                    2,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "        writer.write(frame_out)\n",
    "        frame_idx += 1\n",
    "\n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Processed frame {frame_idx}/{total_frames}\")\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"video\", \"frame\", \"time_sec\", \"time_hms\", \"class_id\", \"class_name\", \"score\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\", \"mask_area_px\", \"img_w\", \"img_h\"\n",
    "    ])\n",
    "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    ratio = (frames_with_detections / max(1, total_frames)) * 100.0\n",
    "    with open(out_sum, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Video: {base}\\n\")\n",
    "        f.write(f\"FPS(input): {input_fps:.2f}\\n\")\n",
    "        f.write(f\"FPS(output): {output_fps:.2f}\\n\")\n",
    "        f.write(f\"Frames: {total_frames}\\n\")\n",
    "        f.write(f\"Frames with detections: {frames_with_detections} ({ratio:.2f}%)\\n\")\n",
    "        f.write(f\"Processing time: {elapsed:.2f}s\\n\")\n",
    "        f.write(f\"Output video: {out_video}\\n\")\n",
    "        f.write(f\"CSV: {out_csv}\\n\")\n",
    "\n",
    "    print(\"âœ… Done\")\n",
    "    print(\"   â†’\", out_video)\n",
    "    print(\"   â†’\", out_csv)\n",
    "    print(\"   â†’\", out_sum)\n",
    "\n",
    "    return out_video\n",
    "\n",
    "print(\"âœ… process_video function loaded successfully.\")"
   ],
   "metadata": {
    "id": "INmGjqa_vTx6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Run processing and display video",
   "metadata": {
    "id": "E5GhRpUuz7R4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "OUTPUT_DIR = \"/content/seg_outputs\"\n",
    "\n",
    "# Video 1\n",
    "CONFIG_PATH_1 = \"/content/config.yaml\"\n",
    "WEIGHTS_PATH_1 = \"/content/model_final.pth\"\n",
    "VIDEO_INPUT_PATH_1 = \"/content/7252.mp4\"\n",
    "SLOTS_JSON_PATH_1 = \"/content/7252_slots.json\"\n",
    "\n",
    "# Video 2\n",
    "CONFIG_PATH_2 = \"/content/config.yaml\"\n",
    "WEIGHTS_PATH_2 = \"/content/model_final.pth\"\n",
    "VIDEO_INPUT_PATH_2 = \"/content/7254.mp4\"\n",
    "SLOTS_JSON_PATH_2 = \"/content/7252_slots.json\"\n",
    "\n",
    "print(f\"ðŸš€ Starting processing for VIDEO 1: {VIDEO_INPUT_PATH_1}\")\n",
    "# Call the processing function for video 1\n",
    "output_avi_path_1 = process_video(\n",
    "    config_path=CONFIG_PATH_1,\n",
    "    weights_path=WEIGHTS_PATH_1,\n",
    "    input_video=VIDEO_INPUT_PATH_1,\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    score_thresh=0.5,\n",
    "    use_visualizer=False,\n",
    "    slots_json_path=SLOTS_JSON_PATH_1,\n",
    "    draw_slots=True if SLOTS_JSON_PATH_1 else False\n",
    ")\n",
    "\n",
    "output_mp4_path_1 = os.path.splitext(output_avi_path_1)[0] + \".mp4\"\n",
    "print(f\"\\n--- Converting {output_avi_path_1} to {output_mp4_path_1} for display ---\")\n",
    "!ffmpeg -i $output_avi_path_1 -vcodec libx264 $output_mp4_path_1 -y -loglevel quiet\n",
    "\n",
    "print(\"âœ… Conversion complete. Displaying Video 1:\")\n",
    "mp4_1 = open(output_mp4_path_1,'rb').read()\n",
    "data_url_1 = \"data:video/mp4;base64,\" + b64encode(mp4_1).decode()\n",
    "display(HTML(f\"\"\"\n",
    "<video width=800 controls autoplay loop>\n",
    "      <source src=\"{data_url_1}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"))\n",
    "\n",
    "print(f\"ðŸš€ Starting processing for VIDEO 2: {VIDEO_INPUT_PATH_2}\")\n",
    "# Call the processing function for video 2\n",
    "output_avi_path_2 = process_video(\n",
    "    config_path=CONFIG_PATH_2,\n",
    "    weights_path=WEIGHTS_PATH_2,\n",
    "    input_video=VIDEO_INPUT_PATH_2,\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    score_thresh=0.5,\n",
    "    use_visualizer=False,\n",
    "    slots_json_path=SLOTS_JSON_PATH_2,\n",
    "    draw_slots=True if SLOTS_JSON_PATH_2 else False\n",
    ")\n",
    "\n",
    "output_mp4_path_2 = os.path.splitext(output_avi_path_2)[0] + \".mp4\"\n",
    "print(f\"\\n--- Converting {output_avi_path_2} to {output_mp4_path_2} for display ---\")\n",
    "!ffmpeg -i $output_avi_path_2 -vcodec libx264 $output_mp4_path_2 -y -loglevel quiet\n",
    "\n",
    "print(\"âœ… Conversion complete. Displaying Video 2:\")\n",
    "mp4_2 = open(output_mp4_path_2,'rb').read()\n",
    "data_url_2 = \"data:video/mp4;base64,\" + b64encode(mp4_2).decode()\n",
    "display(HTML(f\"\"\"\n",
    "<video width=800 controls autoplay loop>\n",
    "      <source src=\"{data_url_2}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"))"
   ],
   "metadata": {
    "id": "K_FjRAWzz9WB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Compress and load results",
   "metadata": {
    "id": "xlxZFpku1lUZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Processing complete!\")\n",
    "print(f\"Results have been saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "ZIP_PATH = \"/content/seg_outputs.zip\"\n",
    "\n",
    "print(f\"Compressing results to {ZIP_PATH}...\")\n",
    "\n",
    "shutil.make_archive(\n",
    "    base_name=ZIP_PATH.replace(\".zip\", \"\"),\n",
    "    format='zip',\n",
    "    root_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(f\"Compression complete! Preparing for download...\")\n",
    "\n",
    "files.download(ZIP_PATH)"
   ],
   "metadata": {
    "id": "jhZhlZHV1m5K"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
